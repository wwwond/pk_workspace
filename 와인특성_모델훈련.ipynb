{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 와인 전체 특성을 사용한 훈련, 예측, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 와인 전체 데이터셋 읽어들이기\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n<딕셔너리에서 사용하는 key>\\n - feature_name : 특성이름\\n - data : 특성에 대한 데이터(특성 데이터, 독립변수)\\n - target : 종속변수\\n - target_names : 종속변수 범주 데이터\\n                : class_0 : 레드와인\\n                : class_1 : 화이트와인\\n                : class_2 : ? (사용안함)\\n\\n<와인 성분에 포함된 화학조성 특성>\\n'alcohol' : 알콜도수\\n'malic_acid' : 말산\\n'ash' : 회분\\n'alcalinity_of_ash' : 회분의 알칼리도\\n'magnesium' : 마그네슘\\n'total_phenols' : 총 포리페놀\\n'flavanoids' : 플라보노이드 폴리페놀\\n'nonflavanoid_phenols' : 비 프라보노이드 폴리페놀\\n'proanthocyanins' : 프로안토시아닌\\n'color_intensity' : 색상 강도\\n'hue' : 색상\\n'od280/od315_of_diluted_wines' : 희석와인의 비율\\n'proline : 프롤린\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "<딕셔너리에서 사용하는 key>\n",
    " - feature_name : 특성이름\n",
    " - data : 특성에 대한 데이터(특성 데이터, 독립변수)\n",
    " - target : 종속변수\n",
    " - target_names : 종속변수 범주 데이터\n",
    "                : class_0 : 레드와인\n",
    "                : class_1 : 화이트와인\n",
    "                : class_2 : ? (사용안함)\n",
    "\n",
    "<와인 성분에 포함된 화학조성 특성>\n",
    "'alcohol' : 알콜도수\n",
    "'malic_acid' : 말산\n",
    "'ash' : 회분\n",
    "'alcalinity_of_ash' : 회분의 알칼리도\n",
    "'magnesium' : 마그네슘\n",
    "'total_phenols' : 총 포리페놀\n",
    "'flavanoids' : 플라보노이드 폴리페놀\n",
    "'nonflavanoid_phenols' : 비 프라보노이드 폴리페놀\n",
    "'proanthocyanins' : 프로안토시아닌\n",
    "'color_intensity' : 색상 강도\n",
    "'hue' : 색상\n",
    "'od280/od315_of_diluted_wines' : 희석와인의 비율\n",
    "'proline : 프롤린\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### 튜닝 자리 \n",
    "gridParams={}\n",
    "gridParams[\"max_depth\"] = [50, 100, 150, 200]\n",
    "gridParams[\"C\"] = 0.5\n",
    "gridParams[\"random_state\"] = [42]\n",
    "n_jobs = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 13) (104,)\n",
      "(26, 13) (26,)\n",
      "모델: KNeighborsClassifier | 차원: 1 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 5}\n",
      "훈련 정확도: 0.9808, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.019230769230769162\n",
      "\n",
      "모델: LogisticRegression | 차원: 1 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'C': 0.1, 'max_iter': 500}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 1 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 10}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.07692307692307687\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 1 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 7}\n",
      "훈련 정확도: 0.9904, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.028846153846153855\n",
      "\n",
      "모델: LogisticRegression | 차원: 1 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'C': 1, 'max_iter': 500}\n",
      "훈련 정확도: 0.9904, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.028846153846153855\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 1 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 5}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.07692307692307687\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 1 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 3}\n",
      "훈련 정확도: 0.9712, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.009615384615384581\n",
      "\n",
      "모델: LogisticRegression | 차원: 1 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'C': 0.1, 'max_iter': 500}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.07692307692307687\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 1 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 5}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.07692307692307687\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 2 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 5}\n",
      "훈련 정확도: 0.9808, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.0576923076923076\n",
      "\n",
      "모델: LogisticRegression | 차원: 2 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'C': 0.01, 'max_iter': 500}\n",
      "훈련 정확도: 0.9904, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.028846153846153855\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 2 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 3}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 2 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 5}\n",
      "훈련 정확도: 0.9808, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.0576923076923076\n",
      "\n",
      "모델: LogisticRegression | 차원: 2 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'C': 10, 'max_iter': 500}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 2 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 5}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 2 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 3}\n",
      "훈련 정확도: 0.9904, 테스트 정확도: 0.8846\n",
      "과적합 여부: 0.10576923076923084\n",
      "\n",
      "모델: LogisticRegression | 차원: 2 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'C': 0.01, 'max_iter': 500}\n",
      "훈련 정확도: 0.9904, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.06730769230769229\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 2 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 3}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 3 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 5}\n",
      "훈련 정확도: 0.9808, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.0576923076923076\n",
      "\n",
      "모델: LogisticRegression | 차원: 3 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'C': 0.01, 'max_iter': 500}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 3 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 3}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 1.0000\n",
      "과적합 여부: 0.0\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 3 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 5}\n",
      "훈련 정확도: 0.9808, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.019230769230769162\n",
      "\n",
      "모델: LogisticRegression | 차원: 3 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'C': 10, 'max_iter': 500}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 3 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 3}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 1.0000\n",
      "과적합 여부: 0.0\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 3 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 7}\n",
      "훈련 정확도: 0.9423, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.019230769230769162\n",
      "\n",
      "모델: LogisticRegression | 차원: 3 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'C': 0.01, 'max_iter': 500}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 3 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 5}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 1.0000\n",
      "과적합 여부: 0.0\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 4 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 7}\n",
      "훈련 정확도: 0.9808, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.019230769230769162\n",
      "\n",
      "모델: LogisticRegression | 차원: 4 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'C': 0.01, 'max_iter': 500}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 4 | 스케일링: StandardScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 10}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 1.0000\n",
      "과적합 여부: 0.0\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 4 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 5}\n",
      "훈련 정확도: 0.9904, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.028846153846153855\n",
      "\n",
      "모델: LogisticRegression | 차원: 4 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'C': 1, 'max_iter': 500}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 4 | 스케일링: MinMaxScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 10}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 1.0000\n",
      "과적합 여부: 0.0\n",
      "\n",
      "모델: KNeighborsClassifier | 차원: 4 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'n_neighbors': 5}\n",
      "훈련 정확도: 0.9615, 테스트 정확도: 0.9231\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: LogisticRegression | 차원: 4 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'C': 0.01, 'max_iter': 500}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.9615\n",
      "과적합 여부: 0.038461538461538436\n",
      "\n",
      "모델: DecisionTreeClassifier | 차원: 4 | 스케일링: RobustScaler\n",
      "최적 하이퍼파라미터: {'max_depth': 3}\n",
      "훈련 정확도: 1.0000, 테스트 정확도: 0.8846\n",
      "과적합 여부: 0.11538461538461542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 모델 리스트\n",
    "model_list = [\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(max_iter=500),\n",
    "    DecisionTreeClassifier()\n",
    "]\n",
    "\n",
    "# 1. 데이터 로드\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "# 2. class_0과 class_1만 필터링\n",
    "hi = (y == 0) | (y == 1)\n",
    "X_fil = X[hi]\n",
    "y_fil = y[hi]\n",
    "\n",
    "# 3. 데이터 분할 (8:2)\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    X_fil, y_fil, test_size=0.2, random_state=42, stratify=y_fil\n",
    ")\n",
    "\n",
    "print(train_input.shape, train_target.shape)\n",
    "print(test_input.shape, test_target.shape)\n",
    "\n",
    "# 특성공학 (PolynomialFeatures 적용)\n",
    "for degree in range(1, 5):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    train_poly = poly.fit_transform(train_input)\n",
    "    test_poly = poly.transform(test_input)\n",
    "\n",
    "    # 스케일링 적용\n",
    "    scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "    scaler_names = [\"StandardScaler\", \"MinMaxScaler\", \"RobustScaler\"]\n",
    "\n",
    "    for scaler, scaler_name in zip(scalers, scaler_names):\n",
    "        train_scaled = scaler.fit_transform(train_poly)\n",
    "        test_scaled = scaler.transform(test_poly)\n",
    "\n",
    "        for model in model_list:\n",
    "            model_name = model.__class__.__name__  # 모델 이름 확인\n",
    "\n",
    "            # 모델별 하이퍼파라미터 설정\n",
    "            param_grid = {}\n",
    "\n",
    "            if model_name == \"KNeighborsClassifier\":\n",
    "                param_grid = {\"n_neighbors\": [3, 5, 7]}\n",
    "\n",
    "            elif model_name == \"LogisticRegression\":\n",
    "                param_grid = {\"C\": [0.01, 0.1, 1, 10], \"max_iter\": [500]}\n",
    "\n",
    "            elif model_name == \"DecisionTreeClassifier\":\n",
    "                param_grid = {\"max_depth\": [3, 5, 10]}\n",
    "\n",
    "            # GridSearchCV 실행\n",
    "            grid_model = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=5,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            grid_model.fit(train_scaled, train_target)\n",
    "\n",
    "            # 모델 성능 평가\n",
    "            train_score = grid_model.score(train_scaled, train_target)\n",
    "            test_score = grid_model.score(test_scaled, test_target)\n",
    "\n",
    "            print(f\"모델: {model_name} | 차원: {degree} | 스케일링: {scaler_name}\")\n",
    "            print(f\"최적 하이퍼파라미터: {grid_model.best_params_}\")\n",
    "            print(f\"훈련 정확도: {train_score:.4f}, 테스트 정확도: {test_score:.4f}\")\n",
    "            print(f\"과적합 여부: {train_score - test_score}\")\n",
    "            print()\n",
    "            \n",
    "            \n",
    "### (해석) 가장 좋은 모델 \n",
    "# 모델: KNeighborsClassifier | 차원: 3 | 스케일링: MinMaxScaler\n",
    "# 최적 하이퍼파라미터: {'n_neighbors': 5}\n",
    "# 훈련 정확도: 0.9808, 테스트 정확도: 0.9615\n",
    "# 과적합 여부: 0.019230769230769162            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pk_dl_202503_kernel",
   "language": "python",
   "name": "pk_dl_202503"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
